Notwithstanding that the earliest formulation of General Relativity dates back to \(1916\), it had to come a long way before people could really start grasping the key concepts of his theory. Einstein himself knew that very well, when in November \(1919\) -- on the occasion of the famous eclipse that confirmed his theory -- he declared to the New York Times\footnote{Special thanks to Gimmy for the gift of a copy of the original article.} \cite{nyt:lights-all-askew}
\begin{quote}
    \emph{A book for \(12\) wise man. }
    
    \emph{No more in all the World could comprehend it.}
\end{quote}
And he was probably right. Everyday life gives us some intuition about Riemannian geometry, but it does not fully prepare us for Lorentz signature geometry. And, if that wasn't enough, the field equations of General Relativity are notoriously among the most difficult ones, from which it can be hard to extract any insight. Indeed it took no less than \(30\) years for the publication of the result that would open the way to an investigation of the theory without the need to rely on any very specific metric: the Raychaudhuri equation \cite[]{raychaudhuri1955relativistic}. Eventually, with its publication in \(1955\) the golden age of relativity theorems could begin.

Relativity theorems are among the most beautiful and elegant results mathematical physics has gifted us with. In spite of the extreme intricacy of the non linear equations that rule gravitational phenomena, a nice interplay of causality, positivity of energy and geometry, can provide us with a fairly good qualitative understanding of exotic features, such as gravitational collapse and black holes.

Among others, some of the most celebrated results concerning these objects are Penrose's Singularity theorems of \(1965\) \cite[]{penrose1965gravitational}, and the black hole area theorem due to Hawking \cite[]{hawking1972black} in \(1971\). The proofs of these theorems share many points: they are both based on the study of a quantity, the \emph{expansion} \(\theta\), by means precisely of its Raychaudhuri's equation, and with the help of a \emph{pointwise} condition on the Ricci tensor of the spacetime, the Null Energy Condition. The need of a pointwise requirement is soon cleared out: Raychaudhuri equation can be turned into the differential inequality
\begin{equation}
    \label{eq:intro-theta}
    \frac{D}{D\lambda}\theta \le -\frac{\theta^2}{2} - R_{\mu\nu}U^{\mu}U^{\nu}.
\end{equation}
This equation is still very difficult to solve because of the presence of the Ricci tensor \(R_{\mu\nu}\). The key idea is then to wash away the metric dependence by introducing some energy condition of the form 
\begin{equation}
    \label{eq:intro-NEC}
    R_{\mu\nu}U^{\mu}U^{\nu}\ge 0,
\end{equation}
and this condition needs to hold at any point of the spacetime if we want to have any hope of studying the solution of the differential inequality \eqref{eq:intro-theta}. Indeed \eqref{eq:intro-NEC} is precisely the \emph{null convergence condition}, the geometric counterpart of the Null Energy condition once Einstein equations are imposed.

This condition has found many critics from the very early days of its appearance. It is undoubtedly an hypothesis that should look into the physics living onto the geometrical spacetime for its justification. However, it appears it has been introduced more for the technical reason explained above, and a derivation from first principles has always been lacking. Energy conditions are expected to embody features such as the ``attractiveness'' of gravity, or -- even more abstractly -- the stability of the configuration under investigation, but their physical interpretation has always been their weakest point.

Anyway, the Null Energy condition is satisfied by all the ordinary forms of matter -- dust and radiation -- and it is saturated by the cosmological constant, but it appears to be violated when quantum fields come into play.
As early as \(1948\) it was postulated one of its most famous counterexamples, the Casimir effect (even if for an experimental proof we had to wait until \(1997\)), and ironically it is of the same year of Penrose's singularity theorem, \(1965\), the argument showing that any pointwise energy condition is going to be violated by any sort of quantum field.

Should we let singularity's and the area theorems fall into forgetfulness then? Well, even if not intended, the golden age of these results was fading into its background already in the early \(1970s\), and developments in this area remained rather scarce for the following \(40\) years. A new spike of energy was injected in the field by the amazing experimental discovery of gravitational waves in \(2016\): this astonishing detection opens the way to a completely new horizon of possibilities, finally giving us a chance to learn more about that shy force of gravity, that still evades a full UV description.

A particularly amazing result is due to a group of researchers from the Massachussets Institute of Technology in \(2021\): by measuring the mass of two black holes before the merger, and the mass of the resulting one afterwards, they claim to have observationally confirmed Hawking's Area theorem with at least \(95\%\) of confidence~\cite[]{PhysRevLett.127.011103}.

With the beginning of a new age of glory for these studies, new results also came by: even if already postulated long before (in \(1995\)) by Ford and Roman in \cite[]{ford1996averaged}, the first proof of a singularity theorem from a weakened energy conditions emerged in \(2011\)~\cite[]{fewster2011singularity} . This proof still proceeds through the study of the Raychaudhuri's equation, but it is very technical and quite hard to develop, not to mention the limited possibility of applying it more generally. A much more interesting one is from \(2019\) \cite[]{fewster2020new}, and proceeds along a rather different path: through index forms.
From that moment onward quite a few generalisations of singularity theorems came by, proving that indeed they seem to be valid also in a semi-classical framework, where by ``semi-classical'' we intend a classical spacetime geometry with a quantum field theory living over it.

But what about the black hole area theorem instead? No one ever expected this result to generalise to a semi-classical regime. The same Stephen Hawking indeed, in \(1974\) published what is probably his most famous article, ``Particle Creation by Black Holes'' \cite[]{hawking1975particle}. In there he gets to the staggering prediction of Hawking radiation, an emission process through which black holes slowly loose energy, and eventually evaporate. But the area of the horizon of a black hole is in direct relationship with its mass, and hence this prediction immediately sets itself against the previous result of \(1971\).

The key, of course, is the energy condition: black hole evaporation is an intrinsically quantum effect, that brings about a violation of the Null Energy Condition, and therefore the black hole area theorem in its classical form cannot be expected to generalise. Given the similarity of its proof with the one of Penrose's Singularity theorem however, it looked curious that one was expected to break away from and the other one to hold in a semi-classical scenario, so we set out to research if there was any tipping point where a separation of the two theorems would emerge.

Let us then give a brief overview of the work presented in this thesis. Unfortunately the methods and the results we are going to need span a very wide spectrum, and therefore a rather long introduction is unavoidable. The work shall be organised into three main parts: geometrical tools, results from quantum field theory, and finally our original results.

\section{Geometrical tools}
First of all we will need a rather advanced toolkit that can allow us to confidently work with submanifolds embedded in the spacetime. In particular, the notion of second fundamental form, or shape tensor, is needed, and from there trapped surfaces will be introduced. Those are surfaces first defined by Penrose for the proof of his singularity theorem in \(1965\) and have interesting geometrical and topological properties that have been studied throughout many years. We are only going to grasp the surface of their analysis, but in the course of our work we will need a definition different from the one first proposed by Penrose. This is why we are first going to define them by the \emph{mean normal curvature}, and then through the expansion (as originally done by Penrose), thereafter proving their equivalence and then recovering their physical interpretation as ``trapping'' surfaces.
The main references for this chapter will be the books by O'Neill \cite[]{o1983semi} and Wald \cite[]{wald2010general}, but many comments will be made on details of the computations which pinpoint the reason of any discrepancy with the treatment in the literature, or account for any original observation or interpretation of the results.
At the end of the chapter we will dedicate a section to the ladder of causality conditions, introduced to avoid more and more precisely the risk of insurgence of closed causal curves. That will be mainly a section of definitions, but extensive comments will be made to account for the degree to which they appear reasonable.  

As already mentioned, although the introduction of Raychaudhuri's equation played a major role in widening the spectra of validity of many relativity theorems, it soon found its applicability's limit, as generally leading to rather complex differential inequalities, like in \cite[]{fewster2011singularity}.
In particular, this method seemed not exceptionally fit for the aim of studying configurations where the energy condition was expressed in terms of restrictions on integrals over a curve of contractions of the stress-energy tensor. This form of energy conditions was more and more convincingly motivated by the study of properties of several quantum field theories, but it often appears too weak to place strong enough constraints on Raychaudhuri-like equations.

What the Raychaudhuri's equation is used for, is the detection of \emph{focal points}. These are almost meeting points of nearby geodesics, leaving normally from a reference surface \(P\). Geodesics are curves in the spacetime with the special property of minimizing the action (and the length functional), and hence are the curves along which an inertial observer would move (or a light ray free to travel in space). However, we shall see in chapter \ref{ch:focal-points} that geodesics developing a focal point cease to bear that minimizing property beyond it. 
That has much physical relevance because, in particular, any inertial observer that ``intended'' to reach a point on the geodesic \(\gamma\) beyond its eventual focal point \(q\) would venture on a different path, even if \(\gamma\) was a geodesic.
The key-idea is that, in a non-vicious spacetime region, not all the normal geodesics leaving some surface \(P\) can develop a focal point, otherwise points beyond the farthest focal point to \(P\) could not be reached from it. 

We hope that this motivation has at least partially outlined why it is very important for the proof of many relativity theorems, to develop a criteria that can tell us if a geodesic is going to develop a focal point to the surface \(P\), and eventually can even tell us where it will form. The Raychaudhuri equation was doing exactly that by studying the quantity \(\theta\): wherever a divergence was developing, it was a signal of a formation of a focal point.

Following the work of O'Neill instead, we will present an alternative method (the \emph{index form method}), that works directly with the minimization of the action functional, and develops a criteria which passes through an integral inequality, rather than a differential one. This difference will become crucial for the applicability of averaged energy conditions: it will be much easier in fact to apply them to a criteria which is already expressed in an integral form, instead of trying to place restrictions on a differential inequality.

We are also going to briefly review the interplay between the two methods, and find that the Raychaudhuri equation is, in some sense, the Euler-Lagrange equation of the functional arising from the Index form method. Witten has been writing a very nice review on these topics as well \cite[]{witten2020light}, and we are going to briefly review his additional geometrical insights into the matter. Additionally, even if working with Raychaudhuri's equation, he tries to ``integrate'' it as well, but unfortunately doesn't get to the final development of the functional of interest, as he doesn't manage to rewrite a surface term in a sufficiently expressive way.

\section{Quantum Field Theory insights}
Einstein equation, in principle, allow the existence of any kind of spacetime: given the Ricci tensor in fact, it is enough to construct the appropriate stress tensor that can match it. However, this is in contrast on one side with the fact we believe unphysical -- due to our everyday experience -- spacetimes that allow chronology violations phenomena, as closed timelike curves or ``short'' wormholes, and on the other hand with our knowledge that not all possible kind of matter should exist.

In order to rule out these pathological solutions of Einstein equations then, we need an additional physical input: that should be a strong enough condition to prohibit all the unphysical ones, but weak enough to allow at least all the -- very different indeed -- forms of matter we already know.
It is believed that energy condition would fulfill precisely this purpose, but unfortunately a precise formulation of a definitive condition, and any derivation from first principles is still lacking. They are usually expressed as restrictions on a contraction of the stress-energy tensor with some particular family of causal vectors; this form is believed to elegantly satisfy the above requirements, as it has direct implications on the geometry of the spacetime -- through Einstein equations once again -- but restrictions on the stress tensor seem general enough to be able to include a very wide range of matter forms.

On the other side, the harshest critics to these conditions were due to the difficulty in assigning them a convincing physical interpretation. They are believed to embody some deep feature of matter, such as the ``attractiveness'' of gravity, or more generally some sort of ``stability'' principle of the investigated system.
However, most of them were introduced for the purpose of a specific proof of some relativity theorem, combined with the above mentioned Raychaudhuri's equation, and most often they seemed tailored towards some specific framework, while derivation from first principles have always been a challenge.

In the early days of relativity theorems, the predominant role was played by \emph{pointwise} energy conditions. In this case the chosen contraction of the stress tensor is asked to hold \emph{at any point} of the spacetime. We have already motivated that those are the ones most suited to place restrictions on the solution of the Raychaudhuri's equation, being this last one a differential equation. The weakest one of this condition was proved to be the Null Energy Condition, indeed the one used by Penrose and Hawking for the proofs respectively of the null singularity theorem and the black hole area theorem. However, we have already mentioned that this condition is going to be violated as soon as quantum fields are introduced. But how should such a condition be generalised then?

The inevitability of negative energy densities could potentially have dramatic consequences, but it was not until \(1978\) that Ford, before anyone else, realized it. His article eventually opened the way for these conditions to better express the quantized nature of our universe: the first revolutionary idea was that those negative energy fluxes could potentially break the second law of thermodynamics -- one of the most undeniable principles we rely onto -- and hence the magnitude and duration of these effects had to be restricted with an uncertainty principle-like bound, in order to avoid it. That was the first embrional \emph{quantum energy inequality} ever formulated.

Quantum energy inequalities are lower bounds on a weighted averaged of the components of the \emph{renormalized} stress energy tensor. There is good evidence that they would suffice to prove interesting geometric consequences, but unfortunately they are not formulated as a single general condition: they look more as as restrictions whose lower bound depends on the particular field theory under consideration. However, they seem to best embody that physical interpretation of ``stability of the system'' that looked so vague for pointwise conditions: indeed they seem to be of the form of \(H\ge 0\), where \(H\) is the hamiltonian of the field theory under consideration. Having bounded spectrum is the natural stability condition in quantum mechanics: however with a background flat geometries only differences from the ground state energy matter, while in a non trivial gravitational context absolute energies become relevant. As we are not able to arbitrarily translate the energy spectrum then, it looks more natural that we have a negative bound, instead of the familiar zero.

The formulation of those negative bounds however, is problematic for interacting field theories or on curve spacetime backgrounds, due to the difficulties in well-defining a renormalized stress tensor. To relax this issue, another breakthrough idea was needed: this came again from Ford, towards the end of the millennium, and was studied in detail in \cite[]{ford1999quantum}. It had been observed how often local violation of pointwise conditions were compensated -- or even over compensated for -- in other regions of spacetime: from this consideration Ford conjectured the \emph{quantum interest} effect. Specifically they give rise to those that have been called \emph{averaged inequalities}. Like QEIs they consider weighted averages of the renormalized stress energy tensor, but they also average the contraction over a suitable region of spacetime, typically a casual geodesic. Finally, like pointwise conditions, they insist on a lower bound zero: in this way they try to combine the best of both previous proposals, limiting the most possible well-posedness problems.

In chapter \ref{ch:energy-conditions} we are going to quickly review the history and the state of the art of these conditions through the analysis of examples interesting for our analysis. We will see how it now seems that the golden graal of these studies has finally been found: the \emph{Achronal Averaged Null Energy condition} (AANEC), in fact, seems not to be violated by any known quantum field theory, and proofs from first principles have already been attained in two dimensions. However, this condition imposes averages on full achronal null geodesics, and this is a condition that is going to be too weak for us to make use of it.
Even if we are going to only use achronal null geodesics in fact, we need a restriction on non-biinfinite intervals: it is fine if one of the two limits runs away to \(+\infty\), but we need at least one of them to be finite, because we are going to look at geodesic that \emph{start} from some surface \(P\), as mentioned in the previous section.

We will review then what looks a sensible way to weak that condition, and we will come to the formulation of \emph{Sobolev conditions} and in particular to the \emph{Smeared Null Energy condition} (SNEC). The former are conditions that look very similar to quantum inequalities, but in general are still state-dependent bounds. The latter is still in the form of a Sobolev condition, but it is specifically \emph{state independent}. Both of them are relevant to us because a singularity theorem has been proved from them; moreover SNEC has been proved in the context of gravity induced on a brane, and seems to be satisfied by evaporating black holes as well. Indeed this condition has been conjectured to all in any semi-classical context, but we will see why it can be expected not to hold within a complete theory of quantum gravity, while instead ANEC might aspire to be a consequence of more fundamental properties.

We will start chapter \ref{ch:black-holes} with a step back into geometry. This is the chapter we are going to dedicate to black holes, to finally very briefly review the evaporation process. But in order to \emph{define} a black hole, some more geometry background is needed. 

Quite a few different definitions of black holes have been proposed since the first publication of the Schwarzschild solution in \(1916\): they all share the idea of describing immensely dense objects, from which not even light can escape (actually, the first speculation that \emph{dark objects} of this sort could exists dates back centuries before the formulation of General Relativity, to the late \(1700\)s with Mitchell and Laplace). However, in order to derive our results we are going to need a specific and rather abstract definition, that makes use of global properties of the space. This is the so-called \emph{causal definition} of the black hole region, and it is only applicable in asymptotically flat spacetimes.

Asymptotically flat spacetimes are a class of manifolds for which a \emph{conformal null infinity} can be defined, namely a point where, in ``normal conditions'', all the light should asymptotically escape towards. This idea comes form the analysis of radiation in Minkowski spacetime, but to be generalised it requires some restrictions on the ``asymptotic'' behaviour of the manifold (for causality motivations we only work with non compact manifolds). We shall define the black hole region as simply that portion of spacetime from which a light ray would be prevented to reach the conformal null infinity. In spite of being pretty weak and rather abstract, it seems to most generally capture the idea of a black hole as an object forbidding everything to escape towards ``its exterior region''.

Given that we will move again towards field theory on curved backgrounds, and briefly review Hawking's famous prediction of radiation emission from black holes. The argument doesn't apply only to them actually, but to any region where curvature become extreme. It is due to the fact that two observers, separated by a highly curved region, in general will not agree on a common notion of \emph{time}: in non stationary spacetimes the absence of a common killing vector in fact breaks down any hope for this -- often granted -- feature. A preferential notion of time can be recovered in locally flat regions, such as the asymptotic regions we guaranteed the existence for the definition of black hole. But it is not at all clear that these two notions will match, and in general they won't. In short, this discrepancy has huge consequences on the quantization of the theory in those two separate regions, and in particular would bring the two observers to disagree on the notion of \emph{vacuum} as well: what seems empty for one of them might not look the same for the other. 

The two Fock spaces are connected via a non trivial Bogoliubov transformation. The computation of its coefficients can show how what looks empty for an observer to the asymptotic past of the gravitational collapse, is in fact filled with a thermal radiation for an observer to the asymptotic future, that could measure a well defined temperature of this Planck spectrum, the Hawking temperature \(T_H\). Besides, this also means that this latter observer is perceiving a net flux of radiation, towards himself and away from the black hole. A careful computation of of the consequent luminosity of the black hole can lead to the derivation of its rate of evaporation, the ultimate quantity of interest for us.

Finally, we will very quickly review how the black hole evaporation process imposes deeper reflections of the causal nature of spacetimes. Indeed the supreme causality condition, global hyperbolicity, seems doomed to fail whenever any evaporation process is in play: following some very recent works by Minguzzi \cite[]{minguzzi2020gravitational} and \cite[]{minguzzi2019lorentzian} however, we will argue that quite a few relativity theorems, and in particular our area theorem as well, can be generalized to a more general setting, where the causality assumption is weakened to the topological condition of \emph{past reflectivity} and \emph{openness}.

\section{The Black Hole Area theorem}

After this long journey short through the physics of the past century, let us eventually arrive to present developments.
As anticipated, we wanted to to investigate where and how the classical black hole area theorem would cease to hold. We didn't find any mention of this in previous literature, and therefore all of the following developments should be understood as fully original. The only attempt to weaken the area theorem that we found is due to Lesourd \cite[]{lesourd2018remark}, but he limits to a condition which it is still ``classical'' (we will give a more precise formulation of what we mean by that in the following), and he just re applies a lemma derived by Fewster and Galloway in \cite[]{fewster2011singularity}. Instead, not only our results but also our methods shall aim at a much higher level of generality.

As argued above, the black hole area theorem is expected to break as soon as quantum effects become relevant. What no one ever specified before is \emph{how} it should break. We will generalise the theorem to show that the \emph{instantaneous} rate of change of the horizon's area is always going to be bounded from below, as a consequence of only geometrical arguments. The precise form of the bound instead, is retrieved by means of the energy condition in place. In particular, we will see that under some classes of energy conditions the bound can be negative, and therefore has a chance to solve the tension with black hole evaporation.

The line of arguments we will need to follow to generalise the theorem is rather different from the classical proofs presented before. In order to more didactically introduce the reader to these new sets of result, we shall first propose a new proof of the classical result by Hawking, and of Lesourd's result, by means of the index form method developed in chapter \ref{ch:focal-points}. In particularly this will immediately lead us to define as \emph{classical} all those energy conditions that recover Hawking's classical result, forbidding black hole evaporation. We will briefly try to characterise those conditions, showing that simply allowing \(R_{\mu\nu}U^{\mu}U^{\nu}\) to be negative in some regions -- as Lesourd -- may not be enough to escape the classical domain.

Afterwards, we will show how the rate of of the area of the black holes horizon is going to always be bounded from below, and we will set out to investigate \emph{what} this bound looks like. In particular, the problem will reduce to the minimization of a functional \(J\), that is going to be defined.
Luckily minimization problems is one of the favourite routines for physicist. In front of the inability of recovering the exact form of the bound, because of the two difficulties of a residual metric dependence, and a vast set onto which run the minimization, we shall firstly fall back on what we will call a \emph{variational strategy}.

Our variational strategy shall be composed of two main parts: first, the choice of an appropriate energy condition, that shall erase any metric dependence, and secondly, the designation of a smaller set where the minimization is easier to carried out. In this way we shall always found a upper bound on the infimum we were originally looking for, and therefore a slightly looser lower bound on the original rate of change of the area.

Now that we have outlined a clear strategy, we shall apply it to several possible energy conditions. We start from a general Sobolev condition, as the ones introduced in chapter \ref{ch:energy-conditions}, and we find a ``mathematical'' expression for the minimal bound. We will pick two different sets onto which run the minimization routine: the first -- smaller -- one, will only need an algebraic analysis (we started from it because it had already been studied in \cite[]{fewster2020new}), and then we will move onto a wider one, that will require all the power of functional analysis instead.

Once that we have a precise formulation of the bound, we would like to express it in terms of some physical interesting quantities. We expected it to depend on some global features of the underlying geometry, and as we will choose to work on a background well approximated by the Schwarzschild metric, we will manage to express it only in terms of the Hawking temperature of the black hole.  

In particular, we will first analyse the case of a non-minimally coupled scalar field, and average the stress tensor in the Kubo-Martin-Schwinger thermal state. In this way we will come to the astonishing result of a bound that follows the same \(T^3\) power law as the one derived at the end of chapter~\ref{ch:black-holes} -- from completely different arguments -- for the rate of evaporation of black holes!
In particular, apart from the choice of the thermal state, the temperature power law is given by the computation of a contraction of the stress tensor near the horizon, needed to estimate the quantity \(\rho_0\) (to be defined in \ref{ch:area-theorem}). That computation turned out to be rather thorny, not because it is particularly difficult by itself, but due to the many subtleties one must pay attention when choosing exactly what to compute and how to do it. Even the literature is rather chaotic when performing similar computations, so we shall carefully proceed to calculate the quantity of interest for us in subsection \ref{subsec:rho-0-estimation} and appendix \ref{app:visser}, making use of methods previously developed, but adapting it to our framework, and finally obtaining a result in accordance with other -- independent -- predictions. 

That result looked very promising, so we proceed to test the robustness of our conclusion. Aiming at that, we apply the above procedure starting from the other suitable energy condition, SNEC. The advantage of this condition is that is is state independent, so we don't need to pick any particular quantum state, but from more general assumptions it can be expected to get to weaker conclusions. Indeed we will be able to retrieve a formula for the bound that only depends on the Hawking temperature again, but this time the power law is only quadratic.
In any case, we will argue that this still solves the tension with the phenomena of black hole evaporation, but perhaps the bound obtained is not the strongest possible.
Inspired by the latter analysis, we will try to restrict the general form of state independent energy conditions, by requiring that no tension with the expected evaporation rate arises, but we will only obtain partial results in that.

In the end we will develop a parallel small result that finds application in the field of singularity theorems. As formalized by Senovilla \cite[]{senovilla1998singularity}, a singularity theorem is always structured onto three hypothesis:
\begin{itemize}
    \item[\ding{99}] A causality condition; 
    \item[\ding{99}] an energy condition;
    \item[\ding{99}] an initial, or boundary condition.
\end{itemize}
In the original proof of Penrose's singularity theorem the role of the boundary condition was played by the existence of a trapped surface. Parallely to the weakening of energy conditions, the boundary conditions must be strengthened, and need ask for ``sufficiently'' trapped surfaces instead. It is an old result that those trapped surface, under the null energy condition, needed to hide behind the horizon, in the black hole region; with an evaporating black hole in place, one might wonder if there is hope to find outside the black hole the initial condition necessary to prove a singularity theorem, but we shall show that is indeed a groundless hope.